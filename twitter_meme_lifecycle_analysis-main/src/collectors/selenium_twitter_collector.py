import os
import csv
import time
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from dotenv import load_dotenv
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

class SeleniumTwitterCollector:
    def __init__(self, save_dir, show_browser=True):
        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.save_dir = save_dir
        os.makedirs(self.save_dir, exist_ok=True)

        # .envì—ì„œ íŠ¸ìœ„í„° ê³„ì • ì •ë³´ ë¡œë”©
        load_dotenv()
        self.username = os.getenv("TWITTER_USERNAME")
        self.password = os.getenv("TWITTER_PASSWORD")

        # í¬ë¡¬ ë“œë¼ì´ë²„ ì˜µì…˜ ì„¤ì •
        options = Options()
        if not show_browser:
            options.add_argument("--headless")
        options.add_argument("--window-size=1400,1000")
        options.add_argument("--start-maximized")
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")
        options.add_argument("--lang=ko-KR")
        options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)

        # í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰
        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        print("ğŸŒ ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ë° ì‹¤í–‰ ì™„ë£Œ")

    def load_cookies(self):
        # ì¿ í‚¤ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ìë™ ë¡œê·¸ì¸ ìˆ˜í–‰
        import pickle
        cookie_path = os.path.join("config", "twitter_cookies.pkl")
        if not os.path.exists(cookie_path):
            raise FileNotFoundError("âŒ ì¿ í‚¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € save_twitter_cookies.pyë¡œ ë¡œê·¸ì¸ í›„ ì¿ í‚¤ ì €ì¥í•˜ì„¸ìš”.")

        print("ğŸª íŠ¸ìœ„í„° ì ‘ì† ì¤‘...")
        self.driver.get("https://twitter.com")
        time.sleep(2)

        print("ğŸ”‘ ì¿ í‚¤ ë¡œë”© ì¤‘...")
        with open(cookie_path, "rb") as f:
            cookies = pickle.load(f)
            for cookie in cookies:
                self.driver.add_cookie(cookie)

        print("ğŸ”„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ ì¤‘...")
        self.driver.refresh()
        time.sleep(3)
        print("âœ… ë¡œê·¸ì¸ ì™„ë£Œ!")

    def extract_engagement_counts(self, card):
        # ì¢‹ì•„ìš”, ë¦¬íŠ¸ìœ—, ëŒ“ê¸€ ìˆ˜, ì¡°íšŒìˆ˜ ì¶”ì¶œ í•¨ìˆ˜
        likes = '0'
        retweets = '0'
        replies = '0'
        views = '0'

        try:
            container = card.find_element(By.CSS_SELECTOR, 'div[aria-label*="likes"]')
            aria_label = container.get_attribute('aria-label')
            print("=" * 50)
            print("aria-label ë‚´ìš©:", aria_label)
            print("=" * 50)
            match = re.search(r'(\d+(?:,\d+)?) replies?, (\d+(?:,\d+)?) reposts?, (\d+(?:,\d+)?) likes?,?.*?(\d+(?:,\d+)?) views?', aria_label)
            if match:
                replies, retweets, likes, views = match.groups()
        except Exception as e:
            print(f"[ë””ë²„ê·¸] aria-label íŒŒì‹± ì‹¤íŒ¨: {e}")

        return likes, retweets, replies, views

    def search_posts(self, keyword, max_posts=1000):
        print(f"ğŸ” '{keyword}' ê²€ìƒ‰ ì‹œì‘...")
        self.load_cookies()
        self.driver.get(f"https://twitter.com/search?q={keyword}&src=typed_query&f=top")
        time.sleep(3)

        try:
            WebDriverWait(self.driver, 15).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, 'article[data-testid="tweet"]'))
            )
            print("âœ… íŠ¸ìœ— ìš”ì†Œ ë¡œë”© ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

        posts = []
        seen_urls = set()
        scroll_count = 0
        last_height = self.driver.execute_script("return document.body.scrollHeight")
        
        while len(posts) < max_posts and scroll_count < 100:
            cards = self.driver.find_elements(By.CSS_SELECTOR, 'article[data-testid="tweet"]')
            print(f"ğŸ”„ ìŠ¤í¬ë¡¤ {scroll_count + 1} - {len(cards)}ê°œ íŠ¸ìœ— ê°ì§€ë¨")
            new_count = 0

            for card in cards:
                try:
                    url_elem = card.find_element(By.CSS_SELECTOR, 'a[href*="/status/"]')
                    url = url_elem.get_attribute('href')
                    if url in seen_urls:
                        continue
                    seen_urls.add(url)

                    text_elems = card.find_elements(By.CSS_SELECTOR, 'div[data-testid="tweetText"] span')
                    text = ' '.join([e.text for e in text_elems if e.text.strip()])

                    username = "unknown"
                    username_elems = card.find_elements(By.CSS_SELECTOR, 'div[data-testid="User-Name"] span')
                    for elem in username_elems:
                        if elem.text.strip() and '@' not in elem.text:
                            username = elem.text.strip()
                            break

                    try:
                        timestamp = card.find_element(By.TAG_NAME, 'time').get_attribute('datetime')
                    except:
                        timestamp = datetime.now().isoformat()

                    likes, retweets, replies, views = self.extract_engagement_counts(card)
                    hashtags = ','.join(re.findall(r'#\w+', text))

                    post = {
                        'author': username,
                        'text': text,
                        'hashtags': hashtags,
                        'likes': likes,
                        'retweets': retweets,
                        'replies': replies,
                        'views': views,
                        'created_at': timestamp,
                        'url': url
                    }
                    posts.append(post)
                    new_count += 1

                    print(f"ğŸ“¥ {username}: â¤ï¸{likes} ğŸ”{retweets} ğŸ’¬{replies} ğŸ‘ï¸{views}")

                    if len(posts) >= max_posts:
                        break
                except:
                    continue

            print(f"âœ… ì´ë²ˆ ìŠ¤í¬ë¡¤ì—ì„œ {new_count}ê°œ ìˆ˜ì§‘ë¨")
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(3)
            new_height = self.driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height
            scroll_count += 1

        print(f"ğŸ‰ ì´ {len(posts)}ê°œ íŠ¸ìœ— ìˆ˜ì§‘ ì™„ë£Œ")
        return posts

    def save_posts(self, posts, meme_name):
        # ìˆ˜ì§‘í•œ ê²Œì‹œë¬¼ CSVë¡œ ì €ì¥
        if not posts:
            print("âš ï¸ ì €ì¥í•  ê²Œì‹œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        filename = f"twitter_{meme_name.replace(' ', '_').lower()}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        filepath = os.path.join(self.save_dir, filename)
        with open(filepath, mode='w', encoding='utf-8-sig', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=posts[0].keys())
            writer.writeheader()
            writer.writerows(posts)
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {filepath}")

    def close(self):
        print("ğŸ”š ë¸Œë¼ìš°ì €ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤...")
        time.sleep(2)
        self.driver.quit()
        print("âœ… ì¢…ë£Œ ì™„ë£Œ")
