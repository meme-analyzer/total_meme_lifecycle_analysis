#!/usr/bin/env python3
"""
TOTAL MEME LIFECYCLE ANALYSIS í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
"""

import os
import shutil

def create_project_structure():
    """í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    # ê¸°ë³¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°
    directories = [
        'instagram_meme_lifecycle_analysis',
        'reddit_meme_lifecycle_analysis', 
        'twitter_meme_lifecycle_analysis',
        'integrated_results',
        'integrated_results/reports',
        'integrated_results/figures',
        'integrated_results/summaries'
    ]
    
    print("ğŸ“ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì¤‘...")
    
    for directory in directories:
        dir_path = os.path.join(base_dir, directory)
        os.makedirs(dir_path, exist_ok=True)
        print(f"  âœ… {directory}")
    
    return base_dir

def create_readme():
    """í†µí•© README íŒŒì¼ ìƒì„±"""
    base_dir = os.path.dirname(os.path.abspath(__file__))
    readme_path = os.path.join(base_dir, 'README.md')
    
    readme_content = """# TOTAL MEME LIFECYCLE ANALYSIS

í†µí•© ë°ˆ ìˆ˜ëª… ì£¼ê¸° ë¶„ì„ ì‹œìŠ¤í…œ - Instagram, Reddit, Twitter í”Œë«í¼ í†µí•© ë¶„ì„

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
TOTAL_MEME_LIFECYCLE_ANALYSIS/
â”œâ”€â”€ main.py                              # í†µí•© ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ setup.py                             # í”„ë¡œì íŠ¸ ì„¤ì •
â”œâ”€â”€ README.md                            # ì´ íŒŒì¼
â”œâ”€â”€ integrated_results/                  # í†µí•© ë¶„ì„ ê²°ê³¼
â”‚   â”œâ”€â”€ reports/                         # í†µí•© ë³´ê³ ì„œ
â”‚   â”œâ”€â”€ figures/                         # í†µí•© ì‹œê°í™”
â”‚   â””â”€â”€ summaries/                       # ë¶„ì„ ìš”ì•½
â”œâ”€â”€ instagram_meme_lifecycle_analysis/   # Instagram ë¶„ì„
â”‚   â””â”€â”€ pipeline.py                      # Instagram íŒŒì´í”„ë¼ì¸
â”œâ”€â”€ reddit_meme_lifecycle_analysis/      # Reddit ë¶„ì„  
â”‚   â””â”€â”€ run_pipeline.py                  # Reddit íŒŒì´í”„ë¼ì¸
â””â”€â”€ twitter_meme_lifecycle_analysis/     # Twitter ë¶„ì„
    â””â”€â”€ run_pipeline_twitter.py          # Twitter íŒŒì´í”„ë¼ì¸
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ëŒ€í™”í˜• ëª¨ë“œ (ì¶”ì²œ)
```bash
python main.py
```

### 2. ëª…ë ¹ì–´ ëª¨ë“œ
```bash
# íŠ¹ì • í”Œë«í¼ì—ì„œ ë°ˆ ë¶„ì„
python main.py --meme "chill guy" --platform reddit

# ëª¨ë“  í”Œë«í¼ì—ì„œ ë¶„ì„
python main.py --meme "wojak" --platform all

# ì—¬ëŸ¬ í”Œë«í¼ ì„ íƒ
python main.py --meme "pepe" --platform reddit twitter

# í”Œë«í¼ ìƒíƒœ í™•ì¸
python main.py --list-platforms
```

## ğŸ“Š ì§€ì› í”Œë«í¼

- **Instagram**: `instagram_meme_lifecycle_analysis/pipeline.py`
- **Reddit**: `reddit_meme_lifecycle_analysis/run_pipeline.py`  
- **Twitter**: `twitter_meme_lifecycle_analysis/run_pipeline_twitter.py`

## ğŸ”§ ì„¤ì •

ê° í”Œë«í¼ë³„ ë””ë ‰í† ë¦¬ì—ì„œ ê°œë³„ ì„¤ì • í•„ìš”:
- API í‚¤ ì„¤ì •
- í™˜ê²½ ë³€ìˆ˜ êµ¬ì„±
- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

## ğŸ“ˆ ê²°ê³¼ë¬¼

- **í†µí•© ìš”ì•½**: `integrated_results/summaries/`
- **í”Œë«í¼ë³„ ìƒì„¸ ê²°ê³¼**: ê° í”Œë«í¼ ë””ë ‰í† ë¦¬ ë‚´ `results/` í´ë”

## ğŸ†˜ ë„ì›€ë§

```bash
python main.py --help
```
"""
    
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"ğŸ“ README.md ìƒì„±: {readme_path}")

def check_platform_scripts():
    """ê° í”Œë«í¼ ìŠ¤í¬ë¦½íŠ¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    scripts = {
        'Instagram': 'instagram_meme_lifecycle_analysis/pipeline.py',
        'Reddit': 'reddit_meme_lifecycle_analysis/run_pipeline.py',
        'Twitter': 'twitter_meme_lifecycle_analysis/run_pipeline_twitter.py'
    }
    
    print("\nğŸ” í”Œë«í¼ ìŠ¤í¬ë¦½íŠ¸ í™•ì¸:")
    
    missing_scripts = []
    
    for platform, script_path in scripts.items():
        full_path = os.path.join(base_dir, script_path)
        if os.path.exists(full_path):
            print(f"  âœ… {platform}: {script_path}")
        else:
            print(f"  âŒ {platform}: {script_path} (ì—†ìŒ)")
            missing_scripts.append((platform, script_path))
    
    if missing_scripts:
        print(f"\nâš ï¸  ëˆ„ë½ëœ ìŠ¤í¬ë¦½íŠ¸ {len(missing_scripts)}ê°œ:")
        for platform, path in missing_scripts:
            print(f"  â€¢ {platform}: {path}")
        print(f"\nğŸ“ ëˆ„ë½ëœ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í•´ë‹¹ ë””ë ‰í† ë¦¬ì— ë³µì‚¬í•˜ì„¸ìš”.")
    else:
        print(f"\nâœ… ëª¨ë“  í”Œë«í¼ ìŠ¤í¬ë¦½íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")

def create_sample_config():
    """ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±"""
    base_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(base_dir, 'config.sample.json')
    
    sample_config = {
        "default_platforms": ["reddit"],
        "analysis_settings": {
            "skip_collection": False,
            "skip_visualization": False, 
            "skip_analysis": False
        },
        "output_settings": {
            "integrated_results_dir": "integrated_results",
            "save_summaries": True,
            "generate_reports": True
        },
        "platform_priorities": {
            "reddit": 1,
            "twitter": 2,
            "instagram": 3
        }
    }
    
    import json
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(sample_config, f, ensure_ascii=False, indent=2)
    
    print(f"âš™ï¸  ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")

def main():
    """ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ­ TOTAL MEME LIFECYCLE ANALYSIS ì„¤ì •")
    print("="*50)
    
    # 1. ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
    base_dir = create_project_structure()
    
    # 2. README ìƒì„±
    create_readme()
    
    # 3. ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±
    create_sample_config()
    
    # 4. í”Œë«í¼ ìŠ¤í¬ë¦½íŠ¸ í™•ì¸
    check_platform_scripts()
    
    print(f"\nğŸ‰ ì„¤ì • ì™„ë£Œ!")
    print(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {base_dir}")
    print(f"\në‹¤ìŒ ë‹¨ê³„:")
    print(f"1. ê° í”Œë«í¼ ë””ë ‰í† ë¦¬ì— í•„ìš”í•œ ìŠ¤í¬ë¦½íŠ¸ ë³µì‚¬")
    print(f"2. API í‚¤ ë° í™˜ê²½ ì„¤ì •")
    print(f"3. python main.py ì‹¤í–‰")

if __name__ == "__main__":
    main()